---
title: "Business Statistics End of Term Assessment IB94X0 2024-2025 #1"
author: "5646570"
output:
  html_document:
    toc: true
    toc_depth: 3
---

## Academic Integrity Statement

This work adheres to the principles of academic integrity as outlined by the University of Warwick. I affirm that the analysis and results presented in this assignment are my own, with all sources appropriately credited. I understand that acts of academic misconduct, such as plagiarism, collusion, or contract cheating, violate the university’s regulations and may result in serious consequences. By following the guidelines provided, I strive to maintain the highest standards of honesty and integrity in my academic work, reflecting the values upheld by the University.

## Declaration of use of AI

AI used: ChatGPT

<b>*Why AI was used*</b>: I used AI assistance for enhancing certain aspects of the R code, such as refining syntax for plotting, improving code efficiency, and addressing minor technical errors.

<b>*Which AI was used:*</b> ChatGPT by OpenAI.

<b>*What AI was used for*:</b>
1. To debug and rectify errors within the code while validating the quality and integrity of the dataset.
2. To learn methods for embedding images in R Markdown files, including the syntax for saving plots with ggsave() and png() and using include_graphics() for final report presentation.
3. To explore plotting techniques and various colour pallete available.
4.To gain insights into possible visualization approaches in R to ensure the results are presented clearly and professionally.

<b>*Use of generated content in submission:*</b> *No content generated by AI has been directly* included in this submission. AI was utilized to produce example code, which I then interpreted and adapted to fit the specific requirements of this data and report. I confirm that no significant portion of the work submitted here has been submitted by me for any other assessments in accredited courses.

The AI tool was utilized purely for guidance and learning purposes in code implementation, visualization decisions, and presentation techniques.


## Preface 

## Question 1:

This report <b>examines the key factors influencing cardiovascular disease (CVD) prevalence in England, with a focus on poverty, smoking rates, overweight prevalence, and wellbeing</b>. Through statistical methods such as multiple regression and correlation analysis, the aim is to provide clear insights to guide public health strategies.

## Question 2:

This analysis explores the factors influencing customer satisfaction in a furniture retail company. Using statistical techniques such as linear regression, interaction modeling, and ANOVA, the study examines the effects of staff satisfaction, delivery time, and socioeconomic status (SES) on customer satisfaction. 

________________________________________________________________________________________________________

## Question 1 report:


### 1. Introduction 

The objective of this analysis is <b>to identify the key predictors of cardiovascular disease (CVD) prevalence in England. Specifically, we examine how poverty, smoking rates, overweight prevalence, and wellbeing influence CVD</b>. 

The dataset includes metrics for each region, and multiple regression analysis, combined with correlation analysis, is employed to understand these relationships. The results are presented using NHST (Null Hypothesis Significance Testing) and summarized in plain English to facilitate actionable insights.

```{r setup question 1, include=FALSE}
# Loading the required libraries
library(tidyverse)
library(ggplot2)
library(car)
library(corrplot)
library(GGally)
library(knitr)
library(gridExtra)
# Loading dataset from Cardio Vascular Disease CSV file
cvd_dataset <- read.csv("Cardio_Vascular_Disease.csv")
```


```{r Data Description for question 1, echo=TRUE}
# Creating data description table
data_description <- data.frame(
  Variable = c("CVD", "Poverty", "overweight", "smokers", "wellbeing", "area Name", "area Code"),
  Description = c(
    "Prevalence of cardiovascular disease in the region (%)",
    "Percentage of the population living below the poverty line (%)",
    "Percentage of the population classified as overweight (%)",
    "Percentage of the population identified as smokers (%)",
    "Composite score measuring overall quality of life (higher is better)",
    "Name of the geographical area/region",
    "Unique identifier for the geographical area"
  )
)

# Displaying the data description table for better understanding purposes
kable(data_description, align = "l", caption = "Data Description Table")
```

### 2. Data Preparation 
To maintain analytical rigor, removing missing values is the most appropriate choice for this analysis due to its <b>simplicity, the minimal loss of data, and its ability to ensure the accuracy and reliability of statistical methods like multiple regression and correlation analysis</b>.

#### 2.1 Variables Overview
Description of the selected variables (CVD, Poverty, overweight, smokers, wellbeing).

#### 2.2 Loading and Cleaning the Data

 2.2.1 Cleaning and handling missing values.

 2.2.2 Final checks for data integrity.

#### 2.3 No missing values remain after cleaning.

```{r Data Exploration for question 1, echo=FALSE}
# Displaying data structure and summary
str(cvd_dataset)
summary(cvd_dataset)

# Carrying out initial check for duplicate and missing values
sum(duplicated(cvd_dataset)) 
colSums(is.na(cvd_dataset))

# Removing missing values from our dataset
cvd_clean_dataset <- cvd_dataset %>%
  select(area_name, Poverty, CVD, overweight, smokers, wellbeing) %>%
  na.omit() # Missing values were removed from this analysis due to factors like: simplicity, minimal loss of data, and its ability to ensure the accuracy and reliability of statistical methods like multiple regression and correlation analysis.

# Ensuring structure of the dataset for its quality after modification
str(cvd_clean_dataset)
summary(cvd_clean_dataset)

# Performing final checks for data integrity in our cleaned dataset
colSums(is.na(cvd_clean_dataset)) 
```
_____________________________________________________________________________________________________

### 3 Exploratory Data Analysis (EDA)

#### 3.1 Distribution of Variables

 3.1.1 We visualized the distributions of key variables to assess normality and variability.
 3.1.2 Histograms help check for normality, skewness, and outliers, which are critical for ensuring the validity of parametric statistical tests like regression.

```{r Data Analysis for question 1, echo=FALSE}
# Performing a check if percentage values are valid (ensuring percentage should be less than or equal to 100)
cvd_clean_dataset %>%
  select(CVD, Poverty, overweight, smokers) %>%
  summarise_all(~ all(. <= 100)) # Returns TRUE if all values are <= 100
```

#### 3.4 Graphical Interpretation

 3.4.1 <b>*CVD Prevalence*</b>: The histogram shows an approximately normal distribution, with most regions having a moderate CVD prevalence, making it ideal for regression.

 3.4.2 <b>*Overweight and Wellbeing*</b>: Both exhibit bell-shaped distributions, suggesting evenly distributed rates across regions.

 3.4.3 <b>*Poverty*</b>: Slightly right-skewed, indicating some regions have high poverty levels. However, the overall distribution is symmetric enough for reliable analysis.

 3.4.4 <b>*Smokers*</b>: Moderately skewed, with most regions having lower smoking rates. A few regions exhibit higher percentages, potentially influencing CVD prevalence.


```{r Visualising Distribustion of the Dataset cvd, echo=FALSE}
# Performing a visualization of distributions of variables using histograms
cvd_clean_dataset %>%
  select(CVD, Poverty, overweight, smokers, wellbeing) %>%
  pivot_longer(cols = everything(), names_to = "key", values_to = "value") %>%
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram(bins = 30, fill = "pink", color = "black", alpha = 0.7) +
    theme_minimal() +
    labs(title = "Distribution of Variables", x = "Value", y = "Frequency")
```

____________________________________________________________________________________________________


#### 3.5 Descriptive Statistics:

 3.5.1 The variables (CVD, Poverty, overweight, smokers, and wellbeing) are all continuous and approximately normally distributed (confirmed through histograms). Pearson correlation is appropriate under these conditions, as it assumes linearity and normality.

 3.5.2 <b>Pearson correlation</b> is widely used and easy to interpret, making it suitable for public reporting and comparisons.
```{r Correlation Analysis, echo=TRUE}
# Performing Pearson Correlation Analysis between each predictor and CVD
cor_matrix <- cor(cvd_clean_dataset[c("CVD", "Poverty", "overweight", "smokers", "wellbeing")], method = "pearson")
print(cor_matrix)

# Performing a visualization of the resulting correlation matrix of each predictor using corrplot
corrplot(cor_matrix, method = "circle")
```

### 4 Correlation Matrix
Correlations among predictors (e.g., Poverty and Smokers,r=0.50) are moderate, which suggests some overlap but not strong multicollinearity.

#### *Key Observations from Correlation Analysis*: 
<b>Strong Correlations</b>:

<b>Poverty and CVD</b>:
A strong positive correlation suggests that *regions with higher poverty rates tend to have higher CVD prevalence*. Poverty emerges as a critical driver of CVD, warranting focused intervention.

<b>Poverty and Smokers</b>:
Higher poverty is *moderately associated with increased smoking rates*, potentially compounding health risks.

<b>Moderate Correlations</b>:

<b>Overweight and CVD</b>:
A moderately positive relationship indicates that overweight prevalence contributes to higher CVD rates, *highlighting the role of obesity management in public health strategies*.

<b>Smokers and CVD</b>:
A moderate positive correlation suggests that smoking behavior is associated with increased CVD prevalence, *though its impact is less pronounced than poverty or overweight*.

<b>Negative Correlations</b>:

<b>Wellbeing and CVD</b>:
A negative correlation suggests that *higher wellbeing scores are associated with lower CVD prevalence*, underlining the protective role of improved quality of life and mental health.

<b>Weak Correlations</b>:

<b>Overweight and Smokers</b>:
While overweight and smokers are weakly correlated, their combined effects on CVD may still be significant.


#### The correlation matrix reveals that <b>*poverty*</b> is the <b>*strongest predictor*</b> of CVD, followed by overweight and smoking rates. Higher wellbeing is associated with reduced CVD prevalence. These insights guide the subsequent regression analysis, where the unique contributions of each predictor are quantified.
____________________________________________________________________________________________________

### 5 Regression Analysis

#### 5.1 <b>Multiple Linear Regression</b>:

To quantify the unique contribution of each predictor to CVD prevalence while accounting for the influence of other predictors.

#### 5.2 <b>Interpretation of Results</b>:

 5.2.1 <b>Poverty</b> (p<0.001): <b>Highly significant</b>. A negative relationship indicates that as poverty decreases (higher socioeconomic status), CVD prevalence increases by 0.184% for every unit increase in poverty.

 5.2.2 <b>Overweight</b> (p<0.001): <b> Highly Significant</b>. A positive relationship shows that a 1% increase in overweight prevalence is associated with a 0.1099% increase in CVD prevalence.

 5.2.3 <b>Smokers</b> (p=0.001): Prevalence contributes a smaller but meaningful increase.

 5.2.4 <b>Wellbeing</b> (p=0.015): A strong relationship suggests that higher wellbeing scores are associated with a 1.8% increase in CVD prevalence for every unit increase in wellbeing.

This may seem unexpected and warrants further exploration, possibly due to multicollinearity or an interaction effect.

 5.2.5 Regression provides precise estimates (β) of how much each predictor influences CVD prevalence, enabling actionable insights.


```{r Multiple Regression Analysis, echo=TRUE}
# Performing Multiple regression analysis
model_cvd <- lm(CVD ~ Poverty + overweight + smokers + wellbeing, data = cvd_clean_dataset)
summary(model_cvd)

# Performing a check for multi-collinearity using Variance Inflation Factor (VIF)
vif(model_cvd)
```

#### 5.3 <b>Multicolinearity Check</b>:

Using VIF (Variance Inflation Factor): To ensure that the predictors (Poverty, overweight, smokers, wellbeing) are not highly correlated with each other, which could compromise the interpretability and validity of the regression model.

 5.3.1 <b>All VIF scores are below 5</b>, indicating no significant multicollinearity among the predictors, which validates the use of multiple linear regression for this analysis.

 5.3.2 Ensures the reliability of the regression results, further supporting its use over ANOVA.

____________________________________________________________________________________________________

### 6 Visualization of Results

```{r Resulting Analysis combined, echo=FALSE}

# Load necessary library
library(ggplot2)
library(gridExtra)

# Displaying Scatter Plot 1: Overweight vs. CVD
overweight_scatter_cvd_plot <- ggplot(cvd_clean_dataset, aes(x = overweight, y = CVD)) +
  geom_point(color = "#009E73", alpha = 0.5) + 
  geom_smooth(method = "lm", color = "#D55E00") +
  labs(
    title = "Effect of Overweight on CVD Prevalence",
    x = "Overweight Rate (%)",
    y = "CVD Prevalence (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5) # Adjust font size and centering
  )

# Displaying Scatter Plot 2: Smokers vs. CVD
smokers_scatter_cvd_plot <- ggplot(cvd_clean_dataset, aes(x = smokers, y = CVD)) +
  geom_point(color = "#CC79A7", alpha = 0.5) +
  geom_smooth(method = "lm", color = "#0072B2") +
  labs(
    title = "Effect of Smoking on CVD Prevalence",
    x = "Smoking Rate (%)",
    y = "CVD Prevalence (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5)
  )

# Displaying Scatter Plot 3: Wellbeing vs. CVD
wellbeing_scatter_cvd_plot <- ggplot(cvd_clean_dataset, aes(x = wellbeing, y = CVD)) +
  geom_point(color = "#F0E442", alpha = 0.5) +
  geom_smooth(method = "lm", color = "#009E73") +
  labs(
    title = "Effect of Wellbeing on CVD Prevalence",
    x = "Wellbeing Score",
    y = "CVD Prevalence (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5)
  )

# Displaying Scatter Plot 4: Poverty vs. CVD
poverty_scatter_cvd_plot <- ggplot(cvd_clean_dataset, aes(x = Poverty, y = CVD)) +
  geom_point(color = "#56B4E9", alpha = 0.5) +
  geom_smooth(method = "lm", color = "purple") +
  labs(
    title = "Effect of Poverty on CVD Prevalence",
    x = "Poverty Rate (%)",
    y = "CVD Prevalence (%)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5)
  )

# Arranging all plots in a grid
grid.arrange(
  overweight_scatter_cvd_plot,
  smokers_scatter_cvd_plot,
  wellbeing_scatter_cvd_plot,
  poverty_scatter_cvd_plot,
  ncol = 2
)
```


#### 6.1 Overweight vs. CVD:

- The orange regression line indicates a moderate positive relationship, with regions having higher overweight prevalence also showing higher CVD rates.
- Most data points cluster near the mean, suggesting a consistent effect.
- Outliers in the upper-right quadrant (high overweight and high CVD prevalence) highlight regions needing further analysis.

<b>Conclusion: Overweight prevalence is a critical behavioral factor influencing CVD, supporting the need for obesity management programs.</b>

#### 6.2 Smokers vs. CVD:

- The blue regression line shows a weak to moderate positive relationship, indicating that smoking rates are positively associated with CVD prevalence.
- Data points are more dispersed, reflecting greater variability in the relationship.

<b>Conclusion: Smoking behavior contributes to CVD prevalence, particularly in high-smoking regions, but its impact is smaller compared to poverty and overweight.</b>


#### 6.3 Wellbeing vs. CVD:

- The green regression line indicates a negative relationship, where higher wellbeing scores are associated with lower CVD prevalence.
- This supports the protective role of quality of life and mental health in reducing CVD.
- Outliers in the lower-left quadrant (low wellbeing and low CVD) may represent regions with unique influencing factors.

<b>Conclusion: Wellbeing acts as a protective factor, suggesting that improving overall quality of life can help reduce CVD prevalence.</b>

#### 6.4 Poverty vs. CVD:

- The purple regression line reveals a negative relationship, showing that as poverty rates increase, CVD prevalence decreases.
- Data clustering around the regression line emphasizes poverty as a significant predictor.

<b>Conclusion: Poverty is the strongest predictor of CVD, underscoring the need for targeted public health interventions in high-poverty regions.</b>

____________________________________________________________________________________________________


### 7. Effect of Poverty on CVD

```{r Analysis Poverty vs. CVD, echo=FALSE}
# Presenting a professional Scatter Plot with Fitted Line for showing the prevelance of Poverty on CVD
poverty_scatter_cvd_plot <- ggplot(cvd_clean_dataset, aes(x = Poverty, y = CVD)) +
  geom_point(color = "#56B4E9", alpha = 0.5) +
  geom_smooth(method = "lm", color = "purple") +
  labs(title = "Effect of Poverty on Cardiovascular Disease Prevalence",
       x = "Poverty Rate (%)",
       y = "CVD Prevalence (%)") +
  geom_vline(xintercept = 19.34, lty = 2) +
  geom_hline(yintercept = 12.42, lty = 2) +
  theme_minimal()

# Display the Poverty vs. CVD plot
print(poverty_scatter_cvd_plot)

# Saving it as a PNG file
ggsave("poverty_scatter_cvd_plot.png", plot = poverty_scatter_cvd_plot, width = 10, height = 6, dpi = 300)

```

<b>Findings from the graph</b>:

1. The scatterplot shows a <b>strong negative linear relationship of poverty rates with CVD prevalence</b>, which suggests that higher poverty rates are likely to have disproportionately lower CVD prevalence in those regions and emphasizes poverty as a key socio-economic factor.

2. This observation is unexpected, as higher poverty levels are generally linked to poorer health outcomes, including increased rates of CVD.

3. The dispersion of data points around the regression line suggests that factors beyond poverty may also contribute to CVD prevalence. The shaded area surrounding the line represents the estimation uncertainty. In most sections, the narrow confidence interval suggests that the model’s predictions are relatively accurate along the regression line.

_______________________________________________________________________________________________________________

### 8. Executive Summary

This report investigates the socioeconomic and behavioral predictors of cardiovascular disease (CVD) prevalence in England, <b>focusing on poverty, smoking rates, overweight prevalence, and wellbeing scores</b>. 

Multiple regression analysis reveals that <b>*poverty is the strongest predictor of CVD prevalence</b>, followed by overweight prevalence and smoking rates, while higher wellbeing is associated with lower CVD prevalence*. The findings emphasize the need for targeted public health interventions addressing poverty and behavioral factors like smoking and obesity.


______________________________________________________________________________________________________

### 9. Conclusion 

1. <b>Poverty</b> has the most significant impact on CVD prevalence, emphasizing the critical role of socioeconomic inequalities.

2. <b>Overweight and Smoking</b> are notable contributors to CVD, reflecting the importance of addressing behavioral risk factors.

3. <b>Wellbeing</b> There is an unexpectedly weak positive correlation observed. Ideally, higher wellbeing scores would be expected to reduce CVD cases, indicating a negative correlation; however, this is not reflected here. This discrepancy suggests that the “wellbeing” measure may not fully capture the factors that contribute to mitigating CVD risk.
______________________________________________________________________________________________________

### 10. Implications

1. Public health efforts should focus on poverty alleviation, particularly in high-risk regions.

2.	Behavioral interventions such as smoking cessation programs and obesity prevention initiatives are essential.

3.	Promoting mental and social wellbeing can serve as a crucial buffer against CVD.

______________________________________________________________________________________________________


### 11. Key Reflections

1. Poverty strongly correlates with higher CVD prevalence, underlining the need for socioeconomic reforms.

2. Behavioral factors like smoking and overweight prevalence have a compounding impact but are secondary to poverty.

3. The protective effect of wellbeing offers a surprising and hopeful avenue for reducing CVD prevalence, even in disadvantaged regions.


____________________________________________________________________________________________________________

## Question 2 report:

### 1. Introduction

Customer satisfaction is a vital metric for retail businesses, directly influencing customer loyalty and overall performance.

Key aspects of the analysis include:
	•	Evaluating the impact of staff.satisfaction, delivery.time, new_range, and SES_category on customer.satisfaction.
	•	Exploring whether the relationship between delivery.time and customer.satisfaction varies across socioeconomic categories using interaction modeling.
	•	Validating the dataset to ensure quality and consistency.
	•	Visualizing key variables and relationships for better insights.
	•	Applying linear regression and interaction models, with results interpreted using Null Hypothesis Significance Testing (NHST).

The findings, presented through tables, figures, and statistical results, provide actionable insights to enhance customer satisfaction across diverse store contexts.

___________________________________________________________________________________________________________
```{r setup, include=FALSE}
# Loading the required libraries for analysis
library(tidyverse)
library(ggplot2)
library(corrplot)
library(car)
library(knitr)

# Loading dataset from customer satisfaction CSV
data <- read.csv("cust_satisfaction.csv")
```

<b>Data Description table creation</b>

Each variable in the dataset is described in a table to provide clarity about its nature and role. This ensures a clear understanding of the dataset before beginning the analysis.

```{r Data Description, echo=TRUE}
# Creating data description table
data_description <- data.frame(
  Variable = c("customer_satisfaction", "staff_satisfaction", "delivery_time", "product_range", "SES"),
  Description = c(
    "Average customer satisfaction score (0-10 scale)",
    "Average staff job satisfaction score (0-10 scale)",
    "Average delivery time for large and custom items (in days)",
    "Indicator for whether the store carries a new product range (Yes/No)",
    "Socio-economic status of the store location (Low/Medium/High)"
  )
)

# Displaying the data description table for better understanding purposes
kable(data_description, align = "l", caption = "Data Description Table")
```

____________________________________________________________________________________________________________


### 3. Data Exploration

<b>Data Structure and Quality</b>:
- The data structure was reviewed to confirm variable types, check for missing values, and ensure the dataset’s overall integrity.
- The SES_category variable was converted to a factor, and new_range was transformed into a binary variable to prepare the data for regression analysis.

<b>Purpose</b>:
- These steps ensure the dataset is formatted appropriately for statistical modeling and align with the requirements for conducting accurate regression analysis.

```{r Data Exploration, echo=FALSE}
# Displaying data structure and summary
str(data)
summary(data)

# Performing a check for missing values and duplicates
sum(is.na(data))
nrow(data) - nrow(distinct(data))

# Ensuring structure of the dataset for its quality
str(data)

# Performing the conversion of SES_category to factor
if (!is.factor(data$SES_category)) {
  data$SES_category <- as.factor(data$SES_category)
  message("Converted SES_category to factor.")
}
# Performing the conversion of new_range to binary variable (0 and 1)
# Assuming "Yes" -> 1 and "No" -> 0
data$new_range <- ifelse(data$new_range == "Yes", 1, 0)

# Ensuring structure of the dataset after modification
str(data)
```

____________________________________________________________________________________________________________

### 4. Data Validation

- This step verifies that <b>customer.satisfaction</b> and <b>staff.satisfaction</b> scores are within the expected range of 0 to 10.
- Ensuring valid scores helps maintain data accuracy and prevents errors that could impact the reliability of the analysis.

```{r Data Validation, echo=FALSE}
# Performing a check for scores validation for customer satisfaction and staff satisfaction (assuming max score = 10)
valid_scores <- data %>% select(customer.satisfaction, staff.satisfaction)

# Ensuring score range is within 0 to 10
apply(valid_scores, 2, function(x) all(x >= 0 & x <= 10))
```

____________________________________________________________________________________________________________

### 5. Data Visualisation

The histogram visualizes the distribution of customer.satisfaction and staff.satisfaction.

```{r Data Visualisation, echo=FALSE}
# Performing visualizing distribution of score-related variables using histograms
data %>%
  select(customer.satisfaction, staff.satisfaction) %>%
  pivot_longer(cols = everything(), names_to = "key", values_to = "value") %>%
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram(bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
    theme_minimal() +
    labs(
      title = "Distribution of Satisfaction Scores",
      x = "Score",
      y = "Frequency"
    )

```

- The distributions show most scores concentrated between 4 and 8, <b>indicating a relatively normal pattern without extreme skewness</b>.
- This supports the suitability of linear regression, as the <b>data does not deviate significantly from normality</b>, meeting one of the key assumptions for the analysis.

___________________________________________________________________________________________________________

### 6. Analysing Correlation among variables

<b>Purpose</b>:

The correlation matrix evaluates the relationships between the numerical variables in the dataset (customer.satisfaction, staff.satisfaction, and delivery.time). This step helps identify potential multicollinearity among predictors and provides an initial understanding of how variables relate to customer satisfaction.

<b>Essential Checks that were done before the analysis</b>:

- Numerical Variables: Only numerical variables were included to ensure the correlation coefficients were meaningful and accurate.

```{r Checking Correlation among variables, echo=FALSE}
# Correlation plot for numerical variables

# Selecting numerical variables
numerical_data <- data %>% select(customer.satisfaction, staff.satisfaction, delivery.time)

# Performing calculation of the correlation matrix
corr_matrix <- cor(numerical_data, use = "complete.obs")

# Creating a professional correlation plot
corrplot(
  corr_matrix,
  method = "circle",
  type = "upper",
  tl.col = "black",
  tl.cex = 1,             # Increase text size for better readability
  cl.cex = 1,             # Adjust color legend text size
  number.cex = 0.8,       # Adjust correlation coefficient size
  addCoef.col = "red",  # Add correlation coefficients in black
  title = "Correlation Matrix of Numerical Variables",  # Add a title
  mar = c(0, 0, 2, 0)     # Adjust margins to accommodate the title
)
```

<b>Interpretation</b>:

1.	<b>Positive Correlations</b>:

- staff.satisfaction and customer.satisfaction have a strong positive correlation (~0.6). This suggests that as <b>staff satisfaction improves, customer satisfaction is likely to increase significantly</b>.
	
2.	<b>Negative Correlations</b>:

- delivery.time has a weak negative correlation with customer.satisfaction. This indicates that <b>longer delivery times may slightly reduce customer satisfaction</b>, though the effect is less pronounced.

___________________________________________________________________________________________________________

### 7.Performing Linear Regression

<b>Purpose</b>:

Linear regression was performed to evaluate the relationships between customer.satisfaction (dependent variable)

<b>key predictors</b>: staff.satisfaction, delivery.time, new_range, and SES_category.

```{r Linear Regression, echo=TRUE}
# Performing linear regression
linear_model <- lm(customer.satisfaction ~ staff.satisfaction + delivery.time + new_range + SES_category, data = data)

# Displaying the summary of the model
summary(linear_model)

# Extracting values of adjusted R-squared to check goodness of fit
adj_r_squared <- summary(linear_model)$adj.r.squared
cat("Adjusted R-squared:", adj_r_squared, "\n")

# Performing visualization of regression diagnostics
par(mfrow = c(2, 2))  # Set up a 2x2 grid for diagnostic plots
plot(linear_model)

# Performing extraction of coefficients for reporting
coef_table <- summary(linear_model)$coefficients
library(knitr)
kable(coef_table, caption = "Linear Regression Coefficients for Customer Satisfaction")
```

<b>Significant Predictors</b>:

1.	staff.satisfaction: A positive and statistically significant effect (p < 0.05), indicating that higher staff satisfaction contributes to improved customer satisfaction.

2.	delivery.time: A negative and statistically significant effect (p < 0.05), suggesting that longer delivery times reduce customer satisfaction.

3.	SES_category:
- Medium SES: A significant positive effect compared to the reference group (High SES).
- Low SES: No significant effect compared to the reference group.
	
<b>Interpretation</b>:

<b>This analysis highlights the importance of staff satisfaction as the most impactful predictor of customer satisfaction, followed by delivery time and SES differences.</b>

__________________________________________________________________________________________________________


### 8. Boxplot: Visualizing Outliers

<b>Purpose</b>:

To examine the distribution of numerical variables (customer.satisfaction, staff.satisfaction, and delivery.time) and to detect potential outliers.

```{r Visualising Outliers, echo=FALSE}
# Performing selection of numerical variables for outlier analysis
numerical_columns <- data %>% select(customer.satisfaction, staff.satisfaction, delivery.time)

# Making a long-format data frame for boxplot visualization
long_data <- numerical_columns %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

# Displaying boxplots for all numerical variables
ggplot(long_data, aes(x = Variable, y = Value)) +
  geom_boxplot(fill = "lightblue", color = "black", outlier.color = "red", outlier.size = 2) +
  theme_minimal() +
  labs(
    title = "Boxplots for Numerical Variables to Visualize Outliers",
    x = "Variable",
    y = "Value"
  )
```


<b>Interpretation</b>:

1.	customer.satisfaction:

- The distribution appears consistent with no visible outliers.
- This suggests uniform customer satisfaction scores across the dataset.

2.	staff.satisfaction:

- The boxplot shows no significant outliers and a symmetric distribution, indicating staff satisfaction levels are evenly distributed.

3.	delivery.time:

- Several outliers are visible beyond the upper whisker, indicating stores with delivery times significantly longer than the majority.
- These outliers could affect the regression results and may need further investigation or adjustments (e.g., centering or inclusion of interaction terms).

 <b>Recognizing these outliers ensures their impact is addressed in subsequent analyses like linear regression and ANOVA, as required by the assignment guidelines.</b>

___________________________________________________________________________________________________________

### 9. Evaluating multicolinearity for the defined models

#### VIF Scores for the Base Model

<b>Purpose</b>:
- The Variance Inflation Factor (VIF) is used to check for multicollinearity among predictors (delivery.time and SES_category) in the base model.

```{r Checking VIF scores of base model, echo=TRUE}
# Performing a check on VIF of base model
lm_model <- lm(customer.satisfaction ~ delivery.time + SES_category, data = data)
vif(lm_model)
```

<b>VIF values are 1.03 for both predictors, well below the threshold of 5.</b>

<b>Interpretation:</b>
- No multicollinearity exists between delivery.time and SES_category. These variables are independently contributing to the model.

____________________________________________________________________________________________________________

#### VIF Scores for the Interaction Model 

<b>Purpose</b>:
- To assess multicollinearity in the interaction model that includes the term delivery.time * SES_category.

```{r Checking VIF scores of interaction model, echo=TRUE}
# Performing a check on Interaction model VIF score 
interaction_model <- lm(customer.satisfaction ~ delivery.time * SES_category, data = data)

# Check VIF for the interaction model (only for predictors)
vif(interaction_model)



```

<b>Interpretation</b>:

- The high VIF for the interaction term indicates multicollinearity due to scaling issues. Centering the variables resolves this problem.

____________________________________________________________________________________________________________

#### Performing Centering

<b>Purpose</b>:

- Centering is applied to delivery.time and staff.satisfaction to reduce multicollinearity between interaction terms and main effects.

```{r Centering and re-running the interaction model, echo=TRUE}
# Performing centering on continuous variables for further analysis
data <- data %>%
  mutate(
    delivery.time_centered = delivery.time - mean(delivery.time, na.rm = TRUE),
    staff.satisfaction_centered = staff.satisfaction - mean(staff.satisfaction, na.rm = TRUE)
  )

# Performing Re-fitting on interaction model with centered variables
interaction_model_centered <- lm(
  customer.satisfaction ~ delivery.time_centered * SES_category + staff.satisfaction_centered,
  data = data
)

# Performing a check on VIF scores for the centered interaction model
vif_values_centered <- vif(interaction_model_centered, type = "predictor")

# Displaying VIF values
vif_values_centered
```

<b>Interpretation</b>:

- Centering effectively addresses multicollinearity, ensuring reliable estimates in the interaction model.

___________________________________________________________________________________________________________

#### ANOVA Analysis


<b>Purpose</b>:

1. Significance Testing of Predictors and Interactions:

- ANOVA (Analysis of Variance) used to determine whether the predictors (staff.satisfaction, delivery.time, and SES_category) and their interaction (delivery.time * SES_category) have statistically significant effects on customer.satisfaction.
- It partitions the variability in customer.satisfaction to assess the contribution of each predictor.

2.	Model Comparison:

- ANOVA was applied to compare the base model (without interaction) and the interaction model. This helps evaluate if including the interaction term improves the model’s explanatory power.

```{r Anova Analysis, echo=TRUE}
# Performing ANOVA analysis
anova_model <- aov(customer.satisfaction ~ staff.satisfaction + delivery.time + SES_category, data = data)
anova_summary <- summary(anova_model)
anova(lm_model,interaction_model)
anova_results <- anova(lm_model,interaction_model)

# Performing extraction of ANOVA table
anova_results <- as.data.frame(summary(anova_results)[[1]])

# Displaying the table using kable
anova_results <- as.data.frame(anova_summary[[1]])  # Extracting ANOVA table
kable(anova_results, caption = "ANOVA Results for Customer Satisfaction")

# Assumption checks
par(mfrow = c(1, 2))  # Setting up a 2x1 grid for diagnostic plots
plot(anova_model, which = 1:2)  # Plotting Residuals vs Fitted and Q-Q Plot


```


1. <b>ANOVA Table</b>:

- Predictors staff.satisfaction, delivery.time, and SES_category were statistically significant (p<0.05), confirming their relevance in predicting customer.satisfaction.
- F-statistics indicate the proportion of variance explained by each predictor relative to residual variance.

2.	<b>Model Comparison</b>:

- Adding the interaction term (delivery.time * SES_category) slightly improves model fit, as shown by a marginally significant p-value of 0.059. <b>This suggests that the impact of delivery.time on customer.satisfaction depends on the SES level</b>.

<b>Interpretation</b>:

1.	<b>Key Predictors</b>:

- <b>staff.satisfaction is the most influential predictor of customer.satisfaction, indicating that higher staff satisfaction strongly enhances customer satisfaction</b>.
- delivery.time negatively affects customer.satisfaction, though its effect is smaller in magnitude.
- <b>SES_category plays a significant role, with medium SES stores having higher satisfaction compared to high SES stores</b>.

2.	<b>Interaction Term</b>:

- The interaction term reveals that the relationship between delivery.time and customer.satisfaction varies across SES levels, demonstrating the importance of considering contextual differences in model design.

______________________________________________________________________________________________________

#### Regression for Baseline and Interaction Models

<b>Purpose</b>:

1.	<b>Baseline Model</b>:

- The baseline model evaluates the main effects of delivery.time_centered and SES_category on customer.satisfaction.
- This model excludes interaction terms and assumes the effects of delivery time are consistent across SES categories.

2.	<b>Interaction Model</b>:

- The interaction model includes the term delivery.time_centered * SES_category to assess whether the relationship between delivery.time and customer.satisfaction varies by SES level.

```{r Regression for Baseline and Interaction Models, echo=TRUE}
# Created a Baseline model
base_model <- lm(customer.satisfaction ~ delivery.time_centered + SES_category, data = data)
summary(base_model)

# created an Interaction model
interaction_model <- lm(customer.satisfaction ~ delivery.time_centered * SES_category, data = data)
summary(interaction_model)

# Performing a comparision on both the models
anova(base_model, interaction_model)
```

<b>Results of Baseline Model</b>:

- Results show SES_category and delivery.time_centered are significant predictors (p < 0.05).

<b>Results of Interaction Model</b>:

- The interaction term (delivery.time_centered * SES_category) is marginally significant (p = 0.059), <b>suggesting the effect of delivery time varies across SES categories</b>.


<b>Results on Comparing Models</b>:

- Adding the interaction term improves the model’s fit, but the improvement is only marginally significant (p = 0.059).

<b>Interpretation</b>:

- Delivery time negatively affects customer satisfaction, and SES categories (Medium and Low) significantly influence satisfaction, with Medium SES stores showing higher satisfaction than High SES stores.
- The marginal significance of the interaction term indicates the relationship between delivery time and customer satisfaction varies slightly depending on the SES category.

______________________________________________________________________________________________________

### 10. Diagnostics and Visualization

```{r Diagnostics and Visualization, echo=FALSE}
# Interaction Visualization
ggplot(data, aes(x = delivery.time_centered, y = customer.satisfaction, color = SES_category)) +
  geom_point() +
  geom_smooth(method = "lm", aes(fill = SES_category), alpha = 0.2) +
  labs(title = "Interaction Effect of Delivery Time and SES on Customer Satisfaction",
       x = "Centered Delivery Time",
       y = "Customer Satisfaction") +
  theme_minimal()

```

<b>Interpreting graph</b>

1.<b>Diagnostics:</b>

Baseline Model:

- Residuals vs. Fitted: The residuals show a random scatter, indicating no major violations of linearity.

Interaction Model:

- Residual diagnostics confirm no significant violations of linear regression assumptions, ensuring the reliability of the results.


Both models satisfy the assumptions of linearity, constant residual variance, and normality, validating their suitability for analysis.


2.<b>Visualization:</b>

Interaction Plot:

- High SES stores: A stronger negative relationship between delivery time and customer satisfaction.
- Medium SES stores: A milder negative relationship.
- Low SES stores: Almost no relationship between delivery time and satisfaction.

Context-Dependent Effects:

- High SES stores are highly sensitive to delivery delays, while Low SES stores are relatively unaffected. Medium SES stores show a moderate impact, emphasizing the need for tailored delivery strategies across socioeconomic levels.
	
	
__________________________________________________________________________________________________________________________________________________________________________________________________________
	
### 11. Summary

This analysis focused on identifying the factors affecting customer satisfaction, specifically examining the roles of staff.satisfaction, delivery.time, and SES_category, along with their interaction. The findings provide meaningful insights for enhancing customer satisfaction across different store contexts.

<b>Key Findings</b>:

1. <b>Significant Predictors</b>:

	•	staff.satisfaction: <b>A strong positive driver of customer satisfaction</b> (p < 0.001). Higher staff satisfaction directly enhances customer experience, highlighting the need for initiatives focused on employee engagement and well-being.
	
	•	delivery.time: <b>Negatively impacts satisfaction</b> (p < 0.05). Longer delivery times reduce customer satisfaction, though the effect is less significant compared to staff satisfaction.
	
	•	SES_category: Medium SES stores showed higher satisfaction compared to High SES stores (p < 0.05), while Low SES stores had no significant difference, indicating variations in expectations based on socioeconomic context.
	
	
2. <b>Interaction Effects</b>:

The interaction between delivery.time and SES_category was marginally significant (p = 0.059), suggesting that <b>delivery time impacts satisfaction differently across SES levels</b>:

	•	High SES stores: More negatively impacted by delivery delays, reflecting higher expectations.
	•	Low SES stores: Less affected by delivery time, suggesting greater flexibility or lower expectations.
	•	Medium SES stores: Show a moderate negative effect from delivery delays.
	
3. <b>Model Diagnostics and Comparison</b>:

	•	Diagnostic checks confirmed no violations of regression assumptions, validating the reliability of results.
	•	ANOVA showed that adding the interaction term improved the model’s explanatory power marginally (p = 0.059), with the baseline model explaining ~55% of the variance in satisfaction.
	
______________________________________________________________________________________________________

### 12. Suggestions
1. <b>Focus on Staff Satisfaction</b>:
	
	•	Employee engagement programs and training initiatives should be prioritized to enhance staff satisfaction, as this has the largest impact on customer satisfaction across all stores.
	
2. <b>Improve Delivery Time</b>:

	•	Streamline delivery processes, particularly in High SES stores, where customers are more sensitive to delays. Strategies such as better tracking, faster order fulfillment, and improved communication regarding delivery timelines are recommended.
	
3. <b>Customize Strategies by SES</b>:

	•	Tailor approaches to the socioeconomic context of the store:
	•	High SES stores: Emphasize fast, premium delivery services to meet high expectations.
	•	Low SES stores: Focus on consistency rather than speed, as customers are less sensitive to delays.
	
______________________________________________________________________________________________________

### 13. Conclusion

<b>Staff satisfaction is the most significant factor influencing customer satisfaction</b>, making it a critical area for investment. <b>Delivery time, though less impactful, requires careful attention in High SES stores to meet customer expectations</b>. 

These insights provide actionable strategies to enhance customer satisfaction across different socioeconomic contexts, grounded in robust statistical analysis and evidence.


_______________________________________________________________________________________________________











